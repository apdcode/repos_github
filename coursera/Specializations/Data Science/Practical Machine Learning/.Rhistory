# Timeplots of stocks on same graph
plot(all_returns, plot.type = "single", main = "Returns", col = 1:4, lwd = 1)
abline(h = 0)
#legend(x = "bottomleft", legend = colnames(returns_df), col = 1:4, lwd = 1)
# Chunk 3: Stationarity
# Dickey-Fuller Test01
suppressWarnings(library(urca))
df_test1 <- ur.df(enoyr2017, type = "none", lags = 0)
df_test1
qnorm(c(.01,.05,.1)/2)
summary(df_test1)
# Dickey-Fuller Test02
library(tseries)
enoyr2017_ur_test_level <- suppressWarnings(adf.test(enoyr2017, k = 0))
rhb_adj_ur_test_level <- suppressWarnings(adf.test(hb_adj, k = 0))
mc2017_ur_test_level <- suppressWarnings(adf.test(mc2017, k = 0))
f1by2017_ur_test_level <- suppressWarnings(adf.test(f1by2017, k = 0))
enoyr2017_ur_test_diff <- suppressWarnings(adf.test(diff(enoyr2017), k = 0))
hb_adj_ur_test_diff <- suppressWarnings(adf.test(diff(hb_adj), k = 0))
mc2017_ur_test_diff <- suppressWarnings(adf.test(diff(mc2017), k = 0))
f1by2017_ur_test_diff <- suppressWarnings(adf.test(diff(f1by2017), k = 0))
# Chunk 4: Stationarity_02
# Springer-Verlag Applied Econometrics with R, s 165
# Augmented Dickey-Fuller tester p책 ln niv책
library(tseries)
# Unit Root tests
suppressWarnings(library(data.table))
suppressWarnings(library(gvlma))
#
# suppressWarnings(adf.test(log(enoyr2017)))
# suppressWarnings(adf.test(diff(log(enoyr2017))))
#
# suppressWarnings(adf.test(log(hb_adj)))
# suppressWarnings(adf.test(diff(log(hb_adj))))
#
# suppressWarnings(adf.test(log(mc2017)))
# suppressWarnings(adf.test(diff(log(mc2017))))
#
# suppressWarnings(adf.test(log(f1by2017)))
# suppressWarnings(adf.test(diff(log(f1by2017))))
# Kointegrasjon 1 - niv책
coint01 <- lm(enoyr2017~hb_adj+mc2017+f1by2017)
summary(coint01)
betas01 <- coint01$coef
betas01
equil01 <- betas01[1] + betas01[2]*hb_adj + betas01[3]*mc2017 + betas01[4]*f1by2017
diseq01 <- enoyr2017 - equil01
df2 <- data.frame(df2, equil01, diseq01)
equil01_ts <- zoo(df2$equil01, datey)
diseq01_ts <- zoo(df2$diseq, datey)
coint_cht01 <- merge(enoyr2017,equil01_ts, mc2017)
df_coint_cht01 <- data.frame(coint_cht01)
tail(df_coint_cht01)
chart.TimeSeries(coint_cht01, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
# Prints chart to file, v1
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/graphs_02")
png()
chart.TimeSeries(coint_cht01, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
dev.off()
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/data")
# Prints chart to file, v2
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/graphs_02")
pdf('LangsiktigLikevekt.pdf')
chart.TimeSeries(coint_cht01, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
dev.off()
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/data")
# Kointegrasjon 2 - ln niv책 ------------------------------------------------------------------------------
coint02 <- lm(log(enoyr2017)~log(hb_adj)+log(mc2017)+log(f1by2017))
summary(coint02)
betas02 <- coint02$coef
betas02
resid_ln <- coint02$residuals
resid_ln_ts <- zoo(resid_ln, datey)
#Unit Root test 1
resid_ln_ts_adf <- adf.test(resid_ln, k = 0)
resid_ln_ts_adf
#Unit Root test 2
# Lager lagget resid series
lag0 <- resid_ln
lag1 <- lag0
for (i in 1:length(lag0)){
if (i == 1){
lag1[i] <- 0
}else{
l1 <- (i-1)
lag1[i] <- lag0[l1]
}
# print(paste(i, lag0, lag1, sep = " "))
}
df3 <- data.frame(df2, lag1, lag0)
# chart.TimeSeries(resid_ln_ts, legend.loc = "bottom", main = "", lwd = 1)
equil02 <- betas02[1] + betas02[2]*log(hb_adj) + betas02[3]*log(mc2017) + betas02[4]*log(f1by2017)
diseq02 <- log(enoyr2017) - equil02
df2 <- data.frame(df2, equil02, diseq02)
equil02_ts <- zoo(df3$equil02, datey)
diseq02_ts <- zoo(df3$diseq02, datey)
diseq02_ur_test_diff <- suppressWarnings(adf.test((diseq02), k = 0))
diseq02_ur_test_diff
# lagchart_ip01 <- merge(lag1,lag0)
# chart.TimeSeries(lagchart_ip01, legend.loc = "bottom", main = "", lwd = 1)
#coint_cht02 <- merge(log(enoyr2017),equil02_ts)
#chart.TimeSeries(coint_cht02, legend.loc = "bottom", main = "", lwd = 1)
# Dafaframe for differences + lag1
Datob <- df3$Date2[-1]
lag1b <- lag1[-1]
df_ecm <- data.table(Datob, diff(log(enoyr2017)), diff(log(hb_adj)), diff(log(mc2017)), diff(log(f1by2017)), lag1b)
setnames(df_ecm, old = names(df_ecm), new = c('dato', 'np', 'hb', 'mc', 'gb','ulikevekt'))
df_ecm2 <- df_ecm[-1,]
# Level
lmtest <- (lm(enoyr2017~hb_adj + mc2017 + f1by2017, data = df3))
summary(lmtest)
diag <- gvlma(lmtest)
diag
# Log
lmtest <- (lm(log(enoyr2017)~log(hb_adj) + log(mc2017) + log(f1by2017), data = df3))
summary(lmtest)
diag <- gvlma(lmtest)
diag
ulikevekt <- lmtest$residuals
#ulikevekt <- ulikevekt[-1]
ulikevekt_l1 <- ulikevekt
for (i in 1:length(ulikevekt)){
if (i == 1){
ulikevekt_l1[i] <- 0
}else{
l1 <- (i-1)
ulikevekt_l1[i] <- ulikevekt[l1]
}
# print(paste(i, lag0, lag1, sep = " "))
}
# Legger til kull i bildet
diseq_df <- data.frame(df3$Date2, df3$mc2017, ulikevekt, ulikevekt_l1)
names(diseq_df)
setnames(diseq_df, old = names(diseq_df), new = c('dato', 'kullmarginal', 'ulikevekt', 'ulikevekt_l1'))
names(diseq_df)
datez <- as.Date(diseq_df$dato, "%d-%m-%Y")
ulikevekt_ts <- zoo(diseq_df$ulikevekt,datez)
ulikevekt_l1_ts <- zoo(diseq_df$ulikevekt_l1,datez)
ulikevekt_diff <- zoo((diseq_df$ulikevekt_l1 - diseq_df$ulikevekt), datez)
kullmarginal_ts <- zoo(diseq_df$kullmarginal, datez)
# anchor01
ulikevekts <- merge(ulikevekt_ts, ulikevekt_l1_ts)
#ulikevekts_df <- data.frame(ulikevekts)
#coint_cht02 <- merge(log(enoyr2017),equil02_ts)
par(mfrow=c(1,1))
chart.TimeSeries(ulikevekts, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
chart.TimeSeries(ulikevekt_ts, main = "Ulikevekt Enoyr2017", lwd = 1, grid.color = 0)
chart.TimeSeries(ulikevekt_ts, main = "Ulikevekt Enoyr2017", lwd = 5, grid.color = 1)
#chart.TimeSeries(ulikevekt_ts, legend.loc = "top", lwd = 1, color = "blue", grid.color = 0)
# chart.TimeSeries(ulikevekt_diff, legend.loc = "top", main = "", lwd = 1)
#Diff Log
lmtest <- (lm(diff(log(enoyr2017)) ~ diff(log(hb_adj)) + diff(log(mc2017)) + diff(log(f1by2017)) + ulikevekt_l1[-1], data = df3))
summary(lmtest)
diag <- gvlma(lmtest)
diag
# Chunk 5: WorkBench_01
# enoyr2017 forklart ved hydrologisk balanse
level_hb <- lm(enoyr2017 ~ hb_adj)
summary(level_hb)
equil_hb <- fitted(level_hb)
diseq_hb <- resid(level_hb)
class(diseq_hb)
enoyr_vs_hb <- merge(enoyr2017, equil_hb)
chart.TimeSeries(enoyr_vs_hb, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
#suppressWarnings(chart.TimeSeries(diseq_hb, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0))
coint02 <- lm(log(enoyr2017)~log(hb_adj)+log(mc2017)+log(f1by2017))
betas <- level_hb$coef
equil_hb_adj <- betas[1] + betas[2]*enoyr2017
enoyr2017_vs_hbadj <- merge(enoyr2017, equil_hb_adj)
chart.TimeSeries(enoyr2017_vs_hbadj, legend.loc = "bottom", main = "", lwd = 1)
# Chunk 6: report_results
tail(all_prices)
tail(df_coint_cht01)
# Chunk 7: sensitiviteter_01
par(mfrow=c(1,1))
dlog_enoyr2017 <- diff(log(enoyr2017))
class(dlog_enoyr2017)
class(equil01_ts)
dlog_enoyr2017 <- diff(log(enoyr2017))
dlog_equil01_ts <- diff(log(equil01_ts))
sens01 <- abs(dlog_enoyr2017 / dlog_equil01_ts)
sens01[sens01>10] <- 0
min(sens01, na.rm = TRUE)
sens01[sens01<(-20)] <- 0
# chart.TimeSeries(sens01, legend.loc = "bottom", main = "", lwd = 1,  grid.color = 0)
sens01_up <- sens01[diff(log(enoyr2017))>0]
# chart.TimeSeries(sens01_up, legend.loc = "bottom", main = "", lwd = 1,  grid.color = 0)
tail(sens01)
# Chunk 2: Data01
# Packages
library(PerformanceAnalytics)
library(zoo)
library(tseries)
library(mvtnorm)
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/data")
df1 <- read.table("coint01.txt", sep = ",", header = TRUE)
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017")
names(df1)
length(names(df1))
df1 <- data.frame(df1)
# Justerer noen verdier manuelt for testing
# df1b <- df1
# df1b$hb[716] <- -7.7
# df1 <- df1b
df1 <- df1[c("Dato","hb", "mc2017", "enoyr2017", "f1by2017")]
df2 <- df1
df2$Date2 <-gsub(".", '-', df2$Dato, fixed = T)
df2$hb_adj <- df2$hb + 100
df2 <- df2[complete.cases(df2), ]
df2b <- tail(df2,400)
df2 <- tail(df2,400)
datey <- as.Date(df2$Date2, "%d-%m-%Y")
# TimeSeries
enoyr2017 <- zoo(df2$enoyr2017, datey)
hb <- zoo(df2$hb, datey)
hb_adj <- zoo(df2$hb_adj, datey)
mc2017 <- zoo(df2$mc2017, datey)
f1by2017 <- zoo(df2$f1by2017, datey)
all_prices <- merge(enoyr2017,hb_adj, mc2017, f1by2017)
# colnames(all_prices) = c("ENOQU4", "ENOYZ5", "f1byF5")
# Calculate cc returns as difference in log prices
all_returns = diff(log(all_prices))
# L05C03 - Plotting financial data with PerformanceAnalytics
# Plot returns using the PerformanceAnalytics function chart.TimeSeries().
chart.TimeSeries(all_prices, legend.loc = "bottom", main = "", lwd = 1,  grid.color = 0)
# chart.TimeSeries(all_returns, legend.loc = "bottom", main = "", lwd = 1)
chart.Bar(all_returns, legend.loc = "bottom", main = "")
# Cumulative return plot -
simple_returns = diff(all_prices)/lag(all_prices, k = -1)
chart.CumReturns(simple_returns, legend.loc = "topleft", wealth.index = TRUE,
main = "Indeksert utvikling", lwd = 1, grid.color = "white")
# Timeplots of stocks on seperate graphs
my.panel <- function(...) {
lines(...)
abline(h = 0)
}
plot(all_returns, lwd = 1, panel = my.panel, col = "blue")
# Timeplots of stocks on same graph
plot(all_returns, plot.type = "single", main = "Returns", col = 1:4, lwd = 1)
abline(h = 0)
#legend(x = "bottomleft", legend = colnames(returns_df), col = 1:4, lwd = 1)
# Chunk 3: Stationarity
# Dickey-Fuller Test01
suppressWarnings(library(urca))
df_test1 <- ur.df(enoyr2017, type = "none", lags = 0)
df_test1
qnorm(c(.01,.05,.1)/2)
summary(df_test1)
# Dickey-Fuller Test02
library(tseries)
enoyr2017_ur_test_level <- suppressWarnings(adf.test(enoyr2017, k = 0))
rhb_adj_ur_test_level <- suppressWarnings(adf.test(hb_adj, k = 0))
mc2017_ur_test_level <- suppressWarnings(adf.test(mc2017, k = 0))
f1by2017_ur_test_level <- suppressWarnings(adf.test(f1by2017, k = 0))
enoyr2017_ur_test_diff <- suppressWarnings(adf.test(diff(enoyr2017), k = 0))
hb_adj_ur_test_diff <- suppressWarnings(adf.test(diff(hb_adj), k = 0))
mc2017_ur_test_diff <- suppressWarnings(adf.test(diff(mc2017), k = 0))
f1by2017_ur_test_diff <- suppressWarnings(adf.test(diff(f1by2017), k = 0))
# Chunk 4: Stationarity_02
# Springer-Verlag Applied Econometrics with R, s 165
# Augmented Dickey-Fuller tester p책 ln niv책
library(tseries)
# Unit Root tests
suppressWarnings(library(data.table))
suppressWarnings(library(gvlma))
#
# suppressWarnings(adf.test(log(enoyr2017)))
# suppressWarnings(adf.test(diff(log(enoyr2017))))
#
# suppressWarnings(adf.test(log(hb_adj)))
# suppressWarnings(adf.test(diff(log(hb_adj))))
#
# suppressWarnings(adf.test(log(mc2017)))
# suppressWarnings(adf.test(diff(log(mc2017))))
#
# suppressWarnings(adf.test(log(f1by2017)))
# suppressWarnings(adf.test(diff(log(f1by2017))))
# Kointegrasjon 1 - niv책
coint01 <- lm(enoyr2017~hb_adj+mc2017+f1by2017)
summary(coint01)
betas01 <- coint01$coef
betas01
equil01 <- betas01[1] + betas01[2]*hb_adj + betas01[3]*mc2017 + betas01[4]*f1by2017
diseq01 <- enoyr2017 - equil01
df2 <- data.frame(df2, equil01, diseq01)
equil01_ts <- zoo(df2$equil01, datey)
diseq01_ts <- zoo(df2$diseq, datey)
coint_cht01 <- merge(enoyr2017,equil01_ts, mc2017)
df_coint_cht01 <- data.frame(coint_cht01)
tail(df_coint_cht01)
chart.TimeSeries(coint_cht01, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
# Prints chart to file, v1
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/graphs_02")
png()
chart.TimeSeries(coint_cht01, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
dev.off()
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/data")
# Prints chart to file, v2
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/graphs_02")
pdf('LangsiktigLikevekt.pdf')
chart.TimeSeries(coint_cht01, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
dev.off()
setwd("C:/repos/research/r_analysis/likevekter_enoyr2017/data")
# Kointegrasjon 2 - ln niv책 ------------------------------------------------------------------------------
coint02 <- lm(log(enoyr2017)~log(hb_adj)+log(mc2017)+log(f1by2017))
summary(coint02)
betas02 <- coint02$coef
betas02
resid_ln <- coint02$residuals
resid_ln_ts <- zoo(resid_ln, datey)
#Unit Root test 1
resid_ln_ts_adf <- adf.test(resid_ln, k = 0)
resid_ln_ts_adf
#Unit Root test 2
# Lager lagget resid series
lag0 <- resid_ln
lag1 <- lag0
for (i in 1:length(lag0)){
if (i == 1){
lag1[i] <- 0
}else{
l1 <- (i-1)
lag1[i] <- lag0[l1]
}
# print(paste(i, lag0, lag1, sep = " "))
}
df3 <- data.frame(df2, lag1, lag0)
# chart.TimeSeries(resid_ln_ts, legend.loc = "bottom", main = "", lwd = 1)
equil02 <- betas02[1] + betas02[2]*log(hb_adj) + betas02[3]*log(mc2017) + betas02[4]*log(f1by2017)
diseq02 <- log(enoyr2017) - equil02
df2 <- data.frame(df2, equil02, diseq02)
equil02_ts <- zoo(df3$equil02, datey)
diseq02_ts <- zoo(df3$diseq02, datey)
diseq02_ur_test_diff <- suppressWarnings(adf.test((diseq02), k = 0))
diseq02_ur_test_diff
# lagchart_ip01 <- merge(lag1,lag0)
# chart.TimeSeries(lagchart_ip01, legend.loc = "bottom", main = "", lwd = 1)
#coint_cht02 <- merge(log(enoyr2017),equil02_ts)
#chart.TimeSeries(coint_cht02, legend.loc = "bottom", main = "", lwd = 1)
# Dafaframe for differences + lag1
Datob <- df3$Date2[-1]
lag1b <- lag1[-1]
df_ecm <- data.table(Datob, diff(log(enoyr2017)), diff(log(hb_adj)), diff(log(mc2017)), diff(log(f1by2017)), lag1b)
setnames(df_ecm, old = names(df_ecm), new = c('dato', 'np', 'hb', 'mc', 'gb','ulikevekt'))
df_ecm2 <- df_ecm[-1,]
# Level
lmtest <- (lm(enoyr2017~hb_adj + mc2017 + f1by2017, data = df3))
summary(lmtest)
diag <- gvlma(lmtest)
diag
# Log
lmtest <- (lm(log(enoyr2017)~log(hb_adj) + log(mc2017) + log(f1by2017), data = df3))
summary(lmtest)
diag <- gvlma(lmtest)
diag
ulikevekt <- lmtest$residuals
#ulikevekt <- ulikevekt[-1]
ulikevekt_l1 <- ulikevekt
for (i in 1:length(ulikevekt)){
if (i == 1){
ulikevekt_l1[i] <- 0
}else{
l1 <- (i-1)
ulikevekt_l1[i] <- ulikevekt[l1]
}
# print(paste(i, lag0, lag1, sep = " "))
}
# Legger til kull i bildet
diseq_df <- data.frame(df3$Date2, df3$mc2017, ulikevekt, ulikevekt_l1)
names(diseq_df)
setnames(diseq_df, old = names(diseq_df), new = c('dato', 'kullmarginal', 'ulikevekt', 'ulikevekt_l1'))
names(diseq_df)
datez <- as.Date(diseq_df$dato, "%d-%m-%Y")
ulikevekt_ts <- zoo(diseq_df$ulikevekt,datez)
ulikevekt_l1_ts <- zoo(diseq_df$ulikevekt_l1,datez)
ulikevekt_diff <- zoo((diseq_df$ulikevekt_l1 - diseq_df$ulikevekt), datez)
kullmarginal_ts <- zoo(diseq_df$kullmarginal, datez)
# anchor01
ulikevekts <- merge(ulikevekt_ts, ulikevekt_l1_ts)
#ulikevekts_df <- data.frame(ulikevekts)
#coint_cht02 <- merge(log(enoyr2017),equil02_ts)
par(mfrow=c(1,1))
chart.TimeSeries(ulikevekts, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
chart.TimeSeries(ulikevekt_ts, main = "Ulikevekt Enoyr2017", lwd = 1, grid.color = 0)
chart.TimeSeries(ulikevekt_ts, main = "Ulikevekt Enoyr2017", lwd = 5, grid.color = 1)
#chart.TimeSeries(ulikevekt_ts, legend.loc = "top", lwd = 1, color = "blue", grid.color = 0)
# chart.TimeSeries(ulikevekt_diff, legend.loc = "top", main = "", lwd = 1)
#Diff Log
lmtest <- (lm(diff(log(enoyr2017)) ~ diff(log(hb_adj)) + diff(log(mc2017)) + diff(log(f1by2017)) + ulikevekt_l1[-1], data = df3))
summary(lmtest)
diag <- gvlma(lmtest)
diag
# Chunk 5: WorkBench_01
# enoyr2017 forklart ved hydrologisk balanse
level_hb <- lm(enoyr2017 ~ hb_adj)
summary(level_hb)
equil_hb <- fitted(level_hb)
diseq_hb <- resid(level_hb)
class(diseq_hb)
enoyr_vs_hb <- merge(enoyr2017, equil_hb)
chart.TimeSeries(enoyr_vs_hb, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0)
#suppressWarnings(chart.TimeSeries(diseq_hb, legend.loc = "bottom", main = "", lwd = 1, grid.color = 0))
coint02 <- lm(log(enoyr2017)~log(hb_adj)+log(mc2017)+log(f1by2017))
betas <- level_hb$coef
equil_hb_adj <- betas[1] + betas[2]*enoyr2017
enoyr2017_vs_hbadj <- merge(enoyr2017, equil_hb_adj)
chart.TimeSeries(enoyr2017_vs_hbadj, legend.loc = "bottom", main = "", lwd = 1)
# Chunk 6: report_results
tail(all_prices)
tail(df_coint_cht01)
# Chunk 7: sensitiviteter_01
par(mfrow=c(1,1))
dlog_enoyr2017 <- diff(log(enoyr2017))
class(dlog_enoyr2017)
class(equil01_ts)
dlog_enoyr2017 <- diff(log(enoyr2017))
dlog_equil01_ts <- diff(log(equil01_ts))
sens01 <- abs(dlog_enoyr2017 / dlog_equil01_ts)
sens01[sens01>10] <- 0
min(sens01, na.rm = TRUE)
sens01[sens01<(-20)] <- 0
# chart.TimeSeries(sens01, legend.loc = "bottom", main = "", lwd = 1,  grid.color = 0)
sens01_up <- sens01[diff(log(enoyr2017))>0]
# chart.TimeSeries(sens01_up, legend.loc = "bottom", main = "", lwd = 1,  grid.color = 0)
tail(sens01)
df2$f1by2017
mc2017
f1by2017
setwd("C:/repos_github/coursera/Specializations/Data Science/Practical Machine Learning")
ls()
setwd("C:/repos_github/coursera/Specializations/Data Science/Practical Machine Learning")
ls()
setwd("C:/repos_github/coursera/Specializations/Data Science/Practical Machine Learning")dir()
dir()
library(kernlab)
data(spam)
rm(list=ls())
data(spam)
head(spam)
plot(density(spam6your[spam$type=="nonspam"]),
col = 'blue', main = "", xlab = "Frequency of 'your'")
plot(density(spam$your[spam$type=="nonspam"]),
col = 'blue', main = "", xlab = "Frequency of 'your'")
lines(density(spam6your[spam$type=="spam"]), col = "red")
lines(density(spam$your[spam$type=="spam"]), col = "red")
setwd("C:/repos_github/coursera/Specializations/Data Science/Practical Machine Learning")
dir()
data(spam)
head(spam)
plot(density(spam$your[spam$type=="nonspam"]),
col = 'blue', main = "Spam", xlab = "Frequency of 'your'")
lines(density(spam$your[spam$type=="spam"]), col = "red")
setwd("C:/repos_github/coursera/Specializations/Data Science/Practical Machine Learning")
dir()
data(spam)
head(spam)
plot(density(spam$your[spam$type=="nonspam"]),
col = 'blue', main = "Spam", xlab = "Frequency of 'your'")
lines(density(spam$your[spam$type=="spam"]), col = "red")
col = 'blue', main = "Spam", xlab = "Frequency of")
plot(density(spam$your[spam$type=="nonspam"]),
col = 'blue', main = "Spam", xlab = "Frequency of")
lines(density(spam$your[spam$type=="spam"]), col = "red")
abline(v=0,5, col = "black")
plot(density(spam$your[spam$type=="nonspam"]),
col = 'blue', main = "Spam", xlab = "Frequency of")
lines(density(spam$your[spam$type=="spam"]), col = "red")
# Make simple function.
# Find cutoff value C for number of 'yours' to indicate spam
abline(v=0,5, col = "black")
abline(v=0.5, col = "black")
prediction <- ifelse(spam$your > 0.5, "spam", "nonspam")
df1 <- data.frame(spam)
View(df1)
spam$your
table(prediction, spam$type)/length(spam$type)
table(prediction, spam$type)
length(spam$type)
table(prediction, spam$type)/length(spam$type)
table(prediction, spam$type)/length(spam$type)
prediction
type
table(prediction, spam$type)
spam$type
prediction
table(prediction, spam$type)/length(spam$type)
length(spam$type)
df_prediction1 <- table(prediction, spam$type)/length(spam$type)
df_prediction1 <- data.frame(table(prediction, spam$type)/length(spam$type))
View(df_prediction1)
Accuracy <- df_prediction1$Freq[1]
Accuracy
Accuracy <- df_prediction1$Freq[1] +  df_prediction1$Freq[4]
Accuracy
accuracy
accuracy <- df_prediction1$Freq[1] +  df_prediction1$Freq[4]
accuracy
setwd("C:/repos_github/coursera/Specializations/Data Science/Practical Machine Learning")
dir()
data(spam)
df1 <- data.frame(spam)
head(spam)
plot(density(spam$your[spam$type=="nonspam"]),
col = 'blue', main = "Spam", xlab = "Frequency of 'yours'")
lines(density(spam$your[spam$type=="spam"]), col = "red")
# Make simple function.
# Find cutoff value C for number of 'yours' to indicate spam
abline(v=0.5, col = "black")
prediction <- ifelse(spam$your > 0.5, "spam", "nonspam")
df_prediction1 <- data.frame(table(prediction, spam$type)/length(spam$type))
accuracy <- df_prediction1$Freq[1] +  df_prediction1$Freq[4]
accuracy
